{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataframe libraries, mathematics libraries\n",
    "import pandas as pd #this library contains functions which can manipulate dataframes. \n",
    "import numpy as np #this library contains functions which deal with mathematical operations and functions.\n",
    "import math\n",
    "import re #importing re for regex\n",
    "\n",
    "#visualisation libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "#preprocessing libraries\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#for Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# For Regression Models\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor, HistGradientBoostingRegressor, GradientBoostingRegressor  \n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.decomposition import PCA \n",
    "# Data Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler  # Encoding categorical variables and scaling numerical features\n",
    "from sklearn.model_selection import train_test_split  # Splitting data into train and test sets\n",
    "\n",
    "# Dimensionality Reduction\n",
    "from sklearn.decomposition import PCA  # Principal Component Analysis for feature reduction\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import chi2, mutual_info_classif, SelectKBest  # Feature selection techniques\n",
    "\n",
    "# Ensemble Learning Models\n",
    "from sklearn.ensemble import RandomForestClassifier  # Used for feature importance in tree-based selection\n",
    "\n",
    "# Recursive Feature Elimination\n",
    "from sklearn.feature_selection import RFE  # Used for recursive feature elimination\n",
    "\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unpickle\n",
    "\n",
    "# Encoder\n",
    "ohe_file = r\"C:\\Users\\UKHSM003\\OneDrive - WSP O365\\Projecting Success\\Hackathon\\Hack 24\\Modelling\\OHE_census.pkl\"\n",
    "\n",
    "\n",
    "# Load the pickled object\n",
    "with open(ohe_file, \"rb\") as file:\n",
    "    OHE_model = pickle.load(file)\n",
    "\n",
    "#---\n",
    "\n",
    "\n",
    "# MinMax\n",
    "MinMaxtransformer_pickle_file = r\"C:\\Users\\UKHSM003\\OneDrive - WSP O365\\Projecting Success\\Hackathon\\Hack 24\\Modelling\\MinMaxtransformer.pkl\" \n",
    "\n",
    "# Load the pickled object\n",
    "with open(MinMaxtransformer_pickle_file, \"rb\") as file:\n",
    "    MinMax_model = pickle.load(file)\n",
    "\n",
    "    \n",
    "#---\n",
    "\n",
    "\n",
    "# PCA\n",
    "filename = r\"C:\\Users\\UKHSM003\\OneDrive - WSP O365\\Projecting Success\\Hackathon\\Hack 24\\Modelling\\rfr_remain_work_qty.p\" \n",
    "\n",
    "# Load the pickled object\n",
    "with open(filename, \"rb\") as file:\n",
    "    rfr_model = pickle.load(file)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "schdule = pd.read_csv('joined_TASK_RSRC_WBS_with pivot table on total time difference.csv')\n",
    "schdule = schdule.drop(columns=['cstr_date','act_start_date','act_end_date','expect_end_date','cstr_type',\n",
    "                                'suspend_date','resume_date','float_path','float_path_order',\n",
    "                                'cstr_date2','cstr_type2','act_this_per_work_qty','act_this_per_equip_qty',\n",
    "                                'external_early_start_date','external_late_end_date','create_user','update_user',\n",
    "                                'role_id','shift_id','user_id','pobs_id','email_addr','employee_code','office_phone',\n",
    "                                'other_phone','rsrc_title_name','def_qty_per_hr','cost_qty_type','ot_factor',\n",
    "                                'unit_id','rsrc_notes','load_tasks_flag','level_flag','last_checksum','obs_id','phase_id',\n",
    "                                'ev_user_pct','ev_etc_user_value','orig_cost','indep_remain_total_cost','ann_dscnt_rate_pct',\n",
    "                                'dscnt_period_type','indep_remain_work_qty','anticip_start_date','anticip_end_date',\n",
    "                                'ev_compute_type','ev_etc_compute_type','plan_open_state','act time difference',\n",
    "                                'Unnamed: 112','Unnamed: 113','tmpl_guid'],axis=1)\n",
    "schdule.dropna(subset = ['rsrc_id', 'parent_rsrc_id','guid'], how='any', inplace=True)\n",
    "#DROP THE TARGET VARIABLE FOR THIS EXAMPLE:\n",
    "schdule = schdule.drop(columns=['remain_work_qty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X/y split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = schdule[['task_name',\n",
    " 'total_float_hr_cnt',\n",
    " 'task_code',\n",
    " 'wbs_name',\n",
    " 'seq_num',\n",
    " 'rem_late_end_date',\n",
    " 'wbs_short_name',\n",
    " 'late_end_date',\n",
    " 'rem_late_start_date',\n",
    " 'late_start_date',\n",
    " 'reend_date',\n",
    " 'target_start_date',\n",
    " 'restart_date',\n",
    " 'early_start_date',\n",
    " 'task_id',\n",
    " 'target_end_date',\n",
    " 'early_end_date',\n",
    " 'wbs_id',\n",
    " 'parent_wbs_id',\n",
    " 'guid']]\n",
    "X=X.reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "#splitting X values in to Categoric and Numerical data\n",
    "\n",
    "numerical=[\n",
    "'total_float_hr_cnt','seq_num','task_id']\n",
    "categorical = ['task_name',\n",
    " 'task_code',\n",
    " 'wbs_name',\n",
    " 'wbs_short_name',\n",
    " 'wbs_id',\n",
    " 'parent_wbs_id',\n",
    " 'guid']\n",
    "\n",
    "###############################################################################\n",
    "#associating numerical and categorical data to train, test and validate\n",
    "\n",
    "#if possible, we want to hand-pick our columns - depending on the number of columns we have\n",
    "#split train data\n",
    "X_train_numerical = X[numerical]\n",
    "X_train_categorical_ohe = X[categorical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UKHSM003\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:246: UserWarning: Found unknown categories in columns [0, 1, 4, 5, 6] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Train\n",
    "X_train_normalized = MinMax_model.transform(X_train_numerical)\n",
    "X_train_minmax = pd.DataFrame(X_train_normalized,columns=X_train_numerical.columns)\n",
    "#X_train_minmax.head()\n",
    "\n",
    "\n",
    "# Train\n",
    "encoded_for_p_train = OHE_model.transform(X_train_categorical_ohe).toarray()\n",
    "cols = OHE_model.get_feature_names_out(input_features=X_train_categorical_ohe.columns)\n",
    "X_train_ohe = pd.DataFrame(encoded_for_p_train, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "X_train_scaled_minmax = pd.concat([X_train_minmax,X_train_ohe], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = rfr_model.predict(X_train_scaled_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1816.  , 2614.5 ,  394.  , ...,  243.05, 1254.45,  164.1 ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4541,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "resources = pd.read_csv('joined_TASK_RSRC_WBS_with pivot table on total time difference.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "results  = pd.concat([resources.reset_index(), pd.DataFrame(y_test_pred, columns=['Pred_remainign work'])], axis=1)[['rsrc_short_name', 'Pred_remainign work']]\n",
    "\n",
    "results.to_csv('results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
